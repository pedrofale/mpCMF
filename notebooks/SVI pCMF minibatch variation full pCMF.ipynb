{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVI minibatch variation on the Sparse ZI pCMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pCMF.misc import utils\n",
    "from pCMF.models.pcmf.inferences import cavi_new, svi_new\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import gamma\n",
    "\n",
    "import operator\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "N = 1000 # number of observations\n",
    "P = 20 # observation space dimensionality\n",
    "K = 10 # latent space dimensionality\n",
    "C = 2 # number of clusters\n",
    "\n",
    "# Generate data set\n",
    "z_p = 0.5\n",
    "eps = 5.\n",
    "Y, D, X, R, V, U, clusters = utils.generate_sparse_data(N, P, K, C=C, zero_prob=z_p, noisy_prop=0.5,\n",
    "                                                 eps_U=eps, return_all=True)\n",
    "\n",
    "Y_train, Y_test, U_train, U_test, c_train, c_test = train_test_split(Y, U.T, clusters, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 60. * 60. * 1.\n",
    "S = 30.\n",
    "max_iter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA\n",
    "pca_U = PCA(n_components=K).fit_transform(np.log(Y_train + 1.))\n",
    "pca_tsne = TSNE(n_components=2).fit_transform(pca_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior parameters\n",
    "alpha = np.abs(np.ones((2, K)) + np.random.rand(2, K))\n",
    "beta = np.abs(np.ones((2, P, K)) + np.random.rand(2, P, K))\n",
    "logit_pi_D = np.random.rand(P)\n",
    "pi_D = np.exp(logit_pi_D) / (1. + np.exp(logit_pi_D))\n",
    "logit_pi_S = np.random.rand(P)\n",
    "pi_S = np.exp(logit_pi_S) / (1. + np.exp(logit_pi_S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAVI:\n",
      "Considering zero-inflated counts.\n",
      "Considering loading sparsity.\n",
      "Iteration 0/1. Log-likelihood: 173.850. Elapsed: 0h0m2s\n"
     ]
    }
   ],
   "source": [
    "# Run CAVI and get estimates (pCMF)\n",
    "print('CAVI:')\n",
    "infcavi = cavi_new.CoordinateAscentVI(Y_train, alpha, beta, pi_D=pi_D, pi_S=pi_S, empirical_bayes=True)\n",
    "infcavi.run(n_iterations=max_iter, calc_ll=True, calc_silh=True, clusters=c_train, sampling_rate=S, max_time=T)\n",
    "cavi_U = infcavi.a[0] / infcavi.a[1] # VI estimate is the mean of the variational approximation\n",
    "cavi_V = infcavi.b[0] / infcavi.b[1]\n",
    "cavi_D = infcavi.estimate_D(infcavi.p_D)\n",
    "cavi_S = infcavi.estimate_S(infcavi.p_S)\n",
    "cavi_tsne = TSNE(n_components=2).fit_transform(cavi_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVI-1:\n",
      "Considering zero-inflated counts.\n",
      "Considering loading sparsity.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'StochasticVI' object has no attribute 'logit_p_S'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b2ff8af1a38d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVI-1:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minfsvi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvi_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStochasticVI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_D\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpi_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_S\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpi_S\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mempirical_bayes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minfsvi1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_ll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_silh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msvi1_U\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfsvi1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0minfsvi1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# VI estimate is the mean of the variational approximation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msvi1_V\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfsvi1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0minfsvi1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pCMF/pCMF/models/pcmf/inferences/klqp_new.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, n_iterations, calc_ll, calc_silh, max_time, sampling_rate, clusters)\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                         \u001b[0;31m# Update log-likelihood and silhouette\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pCMF/pCMF/models/pcmf/inferences/svi_new.py\u001b[0m in \u001b[0;36mupdate_parameters\u001b[0;34m(self, it)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_p_S\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempirical_bayes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pCMF/pCMF/models/pcmf/inferences/svi_new.py\u001b[0m in \u001b[0;36mupdate_p_S\u001b[0;34m(self, minibatch_indexes, eta)\u001b[0m\n\u001b[1;32m    121\u001b[0m \t\t\t\t\t\tself.p_D[i, j] * self.r[i, j, k] * self.X[i, j] * (ar[i, k] + br[j, k]))\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0mlogit_p_S\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogit_p_S\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_logit_p_S\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_S\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogit_p_S\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StochasticVI' object has no attribute 'logit_p_S'"
     ]
    }
   ],
   "source": [
    "# Run SVI and get estimates (pCMF)\n",
    "print('SVI-1:')\n",
    "infsvi1 = svi_new.StochasticVI(Y_train, alpha, beta, pi_D=pi_D, pi_S=pi_S, minibatch_size=1, empirical_bayes=True)\n",
    "infsvi1.run(n_iterations=max_iter, calc_ll=True, calc_silh=True, clusters=c_train, sampling_rate=S, max_time=T)\n",
    "svi1_U = infsvi1.a[0] / infsvi1.a[1] # VI estimate is the mean of the variational approximation\n",
    "svi1_V = infsvi1.b[0] / infsvi1.b[1]\n",
    "svi1_D = infsvi1.estimate_D(infsvi1.p_D)\n",
    "svi1_S = infsvi1.estimate_S(infsvi1.p_S)\n",
    "svi1_tsne = TSNE(n_components=2).fit_transform(svi1_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SVI and get estimates (pCMF)\n",
    "print('SVI-50:')\n",
    "infsvi50 = svi_new.StochasticVI(Y_train, alpha, beta, pi_D=pi_D, pi_S=pi_S, minibatch_size=50, empirical_bayes=True)\n",
    "infsvi50.run(n_iterations=max_iter, calc_ll=True, calc_silh=True, clusters=c_train, sampling_rate=S, max_time=T)\n",
    "svi50_U = infsvi50.a[0] / infsvi50.a[1] # VI estimate is the mean of the variational approximation\n",
    "svi50_V = infsvi50.b[0] / infsvi50.b[1]\n",
    "svi50_D = infsvi50.estimate_D(infsvi50.p_D)\n",
    "svi50_S = infsvi50.estimate_S(infsvi50.p_S)\n",
    "svi50_tsne = TSNE(n_components=2).fit_transform(svi50_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SVI and get estimates (pCMF)\n",
    "print('SVI-100:')\n",
    "infsvi100 = svi_new.StochasticVI(Y_train, alpha, beta, pi_D=pi_D, pi_S=pi_S, minibatch_size=100, empirical_bayes=True)\n",
    "infsvi100.run(n_iterations=max_iter, calc_ll=True, calc_silh=True, clusters=c_train, sampling_rate=S, max_time=T)\n",
    "svi100_U = infsvi100.a[0] / infsvi100.a[1] # VI estimate is the mean of the variational approximation\n",
    "svi100_V = infsvi100.b[0] / infsvi100.b[1]\n",
    "svi100_D = infsvi100.estimate_D(infsvi100.p_D)\n",
    "svi100_S = infsvi100.estimate_S(infsvi100.p_S)\n",
    "svi100_tsne = TSNE(n_components=2).fit_transform(svi100_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SVI and get estimates (pCMF)\n",
    "print('SVI-500:')\n",
    "infsvi500 = svi_new.StochasticVI(Y_train, alpha, beta, pi_D=pi_D, pi_S=pi_S, minibatch_size=500, empirical_bayes=True)\n",
    "infsvi500.run(n_iterations=max_iter, calc_ll=True, calc_silh=True, clusters=c_train, sampling_rate=S, max_time=T)\n",
    "svi500_U = infsvi500.a[0] / infsvi500.a[1] # VI estimate is the mean of the variational approximation\n",
    "svi500_V = infsvi500.b[0] / infsvi500.b[1]\n",
    "svi500_D = infsvi500.estimate_D(infsvi500.p_D)\n",
    "svi500_S = infsvi500.estimate_S(infsvi500.p_S)\n",
    "svi500_tsne = TSNE(n_components=2).fit_transform(svi500_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "ax.plot(infcavi.ll_time, label='CAVI')\n",
    "ax.plot(infsvi1.ll_time, label='SVI-1')\n",
    "ax.plot(infsvi50.ll_time, label='SVI-50')\n",
    "ax.plot(infsvi100.ll_time, label='SVI-100')\n",
    "ax.plot(infsvi500.ll_time, label='SVI-500')\n",
    "plt.ylabel('Average log-likelihood')\n",
    "plt.xlabel('Seconds(*{0})'.format(S))\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "ax.plot(infcavi.silh_time, label='CAVI')\n",
    "ax.plot(infsvi1.silh_time, label='SVI-1')\n",
    "ax.plot(infsvi50.silh_time, label='SVI-50')\n",
    "ax.plot(infsvi100.silh_time, label='SVI-100')\n",
    "ax.plot(infsvi500.silh_time, label='SVI-500')\n",
    "plt.ylabel('Silhouette of latent space')\n",
    "plt.xlabel('Seconds(*{0})'.format(S))\n",
    "\n",
    "plt.legend(loc='upper left', bbox_to_anchor=[1., 1.], frameon=True)\n",
    "plt.suptitle('Data set with N={} and P={}'.format(N, P), fontsize=14)\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavi_dll = utils.log_likelihood(Y_train, cavi_U, cavi_V, infcavi.p_D, cavi_S, clip=infcavi.clip_ll)\n",
    "svi1_dll = utils.log_likelihood(Y_train, svi1_U, svi1_V, infsvi1.p_D, svi1_S, clip=infcavi.clip_ll)\n",
    "svi50_dll = utils.log_likelihood(Y_train, svi50_U, svi50_V, infsvi50.p_D, svi50_S, clip=infcavi.clip_ll)\n",
    "svi100_dll = utils.log_likelihood(Y_train, svi100_U, svi100_V, infsvi100.p_D, svi100_S, clip=infcavi.clip_ll)\n",
    "svi500_dll = utils.log_likelihood(Y_train, svi500_U, svi500_V, infsvi500.p_D, svi500_S, clip=infcavi.clip_ll)\n",
    "\n",
    "scores = {'CAVI': cavi_dll, 'SVI-1': svi1_dll, 'SVI-50': svi50_dll, 'SVI-100': svi100_dll, 'SVI-500': svi500_dll}\n",
    "\n",
    "sorted_scores = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "print('Full data log-likelihood:')\n",
    "print('\\033[1m- {0}: {1:.3}\\033[0m'.format(sorted_scores[0][0], sorted_scores[0][1]))\n",
    "for score_tp in sorted_scores[1:]:\n",
    "    print('- {0}: {1:.3}'.format(score_tp[0], score_tp[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavi_holl = infcavi.predictive_ll(Y_test)\n",
    "svi1_holl = infsvi1.predictive_ll(Y_test)\n",
    "svi50_holl = infsvi50.predictive_ll(Y_test)\n",
    "svi100_holl = infsvi100.predictive_ll(Y_test)\n",
    "svi500_holl = infsvi500.predictive_ll(Y_test)\n",
    "svi1000_holl = infsvi1000.predictive_ll(Y_test)\n",
    "\n",
    "scores = {'CAVI': cavi_holl, 'SVI-1': svi1_holl, 'SVI-50': svi50_holl, 'SVI-100': svi100_holl, 'SVI-500': svi500_holl}\n",
    "\n",
    "sorted_scores = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "print('Held-out log-likelihood:')\n",
    "print('\\033[1m- {0}: {1:.3}\\033[0m'.format(sorted_scores[0][0], sorted_scores[0][1]))\n",
    "for score_tp in sorted_scores[1:]:\n",
    "    print('- {0}: {1:.3}'.format(score_tp[0], score_tp[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_silh = silhouette_score(U_train, c_train)\n",
    "cavi_silh = silhouette_score(cavi_U, c_train)\n",
    "svi1_silh = silhouette_score(svi1_U, c_train)\n",
    "svi50_silh = silhouette_score(svi50_U, c_train)\n",
    "svi100_silh = silhouette_score(svi100_U, c_train)\n",
    "svi500_silh = silhouette_score(svi500_U, c_train)\n",
    "pca_silh = silhouette_score(pca_U, c_train)\n",
    "\n",
    "scores = {'CAVI': cavi_silh, 'SVI-1': svi1_silh, 'SVI-50': svi50_silh, 'SVI-100': svi100_silh, \n",
    "          'SVI-500': svi500_silh, 'PCA': pca_silh}\n",
    "\n",
    "sorted_scores = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "print('Silhouette scores (higher is better):')\n",
    "print('\\033[1m- {0}: {1:.3}\\033[0m'.format(sorted_scores[0][0], sorted_scores[0][1]))\n",
    "for score_tp in sorted_scores[1:]:\n",
    "    print('- {0}: {1:.3}'.format(score_tp[0], score_tp[1]))\n",
    "    \n",
    "print('\\nSilhouette of true U:')\n",
    "print('%0.3f' % true_silh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_list = [cavi_tsne, svi1_tsne, svi50_tsne, svi100_tsne, svi500_tsne, pca_tsne]\n",
    "title_list = ['CAVI', 'SVI-1', 'SVI-50', 'SVI-100', 'SVI-500', 'PCA']\n",
    "\n",
    "n_results = len(U_list)\n",
    "\n",
    "assert len(U_list) == len(title_list)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "s = 30\n",
    "alpha = 0.7\n",
    "labels=None\n",
    "for i in range(len(U_list)):\n",
    "    ax = plt.subplot(2, 3, i+1)\n",
    "    handlers = []\n",
    "    for c in range(C):\n",
    "        h = ax.scatter(U_list[title_list.index(sorted_scores[i][0])][c_train==c, 0], U_list[title_list.index(sorted_scores[i][0])][c_train==c, 1], s=s, alpha=alpha)\n",
    "        handlers.append(h)\n",
    "    if labels is not None:\n",
    "        ax.legend(handlers, labels, scatterpoints=1)\n",
    "    plt.title(sorted_scores[i][0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
